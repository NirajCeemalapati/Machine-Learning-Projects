{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0MINcn0n6M2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import twitter_samples\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('twitter_samples')"
      ],
      "metadata": {
        "id": "2Dltl-mHsVlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import twitter_samples\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "D7LhOJGjsVnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "bh8mZJAUsVp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_positive_tweets=twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets=twitter_samples.strings('negative_tweets.json')  #perpare the data\n",
        "tweets=all_positive_tweets + all_negative_tweets"
      ],
      "metadata": {
        "id": "GlhiSDvUsVsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=np.append(np.ones((len(all_positive_tweets))),\n",
        "                 np.zeros((len(all_negative_tweets))))"
      ],
      "metadata": {
        "id": "YpW_V6eVsVuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pos=all_positive_tweets[4000:]\n",
        "train_pos=all_positive_tweets[:4000]\n",
        "test_neg=all_negative_tweets[4000:]\n",
        "train_neg=all_negative_tweets[:4000]\n",
        "train_x=train_pos+train_neg\n",
        "test_x=test_pos+test_neg"
      ],
      "metadata": {
        "id": "Z-X9DqZEsVw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "metadata": {
        "id": "wOHjBxRz0LGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_y.shape = \" + str(train_y.shape))\n",
        "print(\"test_y.shape = \" + str(test_y.shape))"
      ],
      "metadata": {
        "id": "XjojHF5J0LI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and\n",
        "                word not in string.punctuation):\n",
        "            stem_word = stemmer.stem(word)\n",
        "            tweets_clean.append(stem_word)\n",
        "    return tweets_clean\n"
      ],
      "metadata": {
        "id": "5v9jpXPq0LLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_freqs(tweets, ys):\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "    return freqs\n"
      ],
      "metadata": {
        "id": "bCfnBYl50LN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = build_freqs(tweets, labels)\n",
        "print(f'type(freqs) = {type(freqs)}')\n",
        "print(f'len(freqs) = {len(freqs)}')    #word counts"
      ],
      "metadata": {
        "id": "wibrv3s20LQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = ['happi', 'merri', 'nice', 'good', 'bad', 'sad', 'mad', 'best', 'pretti',\n",
        "        '‚ù§', ':)', ':(', 'üòí', 'üò¨', 'üòÑ', 'üòç', '‚ôõ',\n",
        "        'song', 'idea', 'power', 'play', 'magnific']\n",
        "data = []\n",
        "for word in keys:\n",
        "  pos = 0\n",
        "  neg = 0\n",
        "  if (word, 1) in freqs:\n",
        "        pos = freqs[(word, 1)]\n",
        "  if (word, 0) in freqs:\n",
        "        neg = freqs[(word, 0)]\n",
        "  data.append([word, pos, neg])\n",
        "data"
      ],
      "metadata": {
        "id": "OYHV_e370LSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (8, 8))\n",
        "x = np.log([x[1] + 1 for x in data])\n",
        "y = np.log([x[2] + 1 for x in data])\n",
        "ax.scatter(x, y)\n",
        "plt.xlabel(\"Log Positive count\")\n",
        "plt.ylabel(\"Log Negative count\")\n",
        "for i in range(0, len(data)):\n",
        "    ax.annotate(data[i][0], (x[i], y[i]), fontsize=12)\n",
        "ax.plot([0, 9], [0, 9], color = 'red')  # Plot the red line that divides the 2 areas.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xbNjYWkE0LV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = build_freqs(train_x, train_y)\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "metadata": {
        "id": "8iSZPVQI0LYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is an example of a positive tweet: \\n', train_x[0])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
      ],
      "metadata": {
        "id": "r-HBMUU64I_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    h = 1/(1+np.exp(-z))\n",
        "    return h"
      ],
      "metadata": {
        "id": "gCxEX-mh4JBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    m = x.shape[0]\n",
        "    for i in range(0, num_iters):\n",
        "        z = np.dot(x,theta)\n",
        "        h = sigmoid(z)\n",
        "        J = -(np.dot(y.T,np.log(h))+np.dot((1-y).T,np.log(1-h)))/m\n",
        "        theta = theta - alpha*(np.dot(x.T,h-y))/m\n",
        "    J = float(J)\n",
        "    return J, theta"
      ],
      "metadata": {
        "id": "EBmc4utKYI9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    word_l = process_tweet(tweet)\n",
        "    x = np.zeros((1, 3))\n",
        "    x[0,0] = 1\n",
        "    for word in word_l:                  #extract the features\n",
        "        if (word,1.0) in freqs:\n",
        "          x[0,1] += freqs[(word,1.0)]\n",
        "        if(word,0.0) in freqs:\n",
        "            x[0,2] += freqs[(word,0.0)]\n",
        "    return x"
      ],
      "metadata": {
        "id": "2s6TzVt34kVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "Y = train_y\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "BQpjb7ia4JFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {J:.6f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "metadata": {
        "id": "mT87ZkoyX3Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (10, 8))\n",
        "colors = ['red', 'green']\n",
        "\n",
        "ax.scatter(X[:,1], X[:,2], c=[colors[int(k)] for k in Y], s = 0.1)\n",
        "plt.xlabel(\"Positive\")\n",
        "plt.ylabel(\"Negative\")"
      ],
      "metadata": {
        "id": "6OnM8tMv5ubr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neg(theta, pos):\n",
        "    return (-theta[0] - pos * theta[1]) / theta[2]"
      ],
      "metadata": {
        "id": "9lWh-8GAXx41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (10, 8))\n",
        "colors = ['red', 'green']\n",
        "ax.scatter(X[:,1], X[:,2], c=[colors[int(k)] for k in Y], s = 0.1)\n",
        "plt.xlabel(\"Positive\")\n",
        "plt.ylabel(\"Negative\")\n",
        "maxpos = np.max(X[:,1])\n",
        "ax.plot([0,  maxpos], [neg(theta, 0),   neg(theta, maxpos)], color = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3gaOHuuyXx7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "  x = extract_features(tweet, freqs)\n",
        "  y_pred = sigmoid(np.dot(x,theta))\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "Pk8mTUldXx9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'I love machine learning :)'\n",
        "y_pred_temp = predict_tweet(my_tweet, freqs, theta)\n",
        "print(y_pred_temp)\n",
        "if y_pred_temp > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else:\n",
        "    print('Negative sentiment')"
      ],
      "metadata": {
        "id": "g5HZqjSNXyBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "    y_hat = []\n",
        "    for tweet in test_x:\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "        if y_pred > 0.5:\n",
        "            y_hat.append(1.0)\n",
        "        else:\n",
        "            y_hat.append(0.0)\n",
        "    accuracy = np.sum(np.squeeze(test_y) == np.squeeze(np.asarray(y_hat)))/len(test_y)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "-yI9qeOVZak4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "FSXRN6qbZw3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Label Predicted Tweet')\n",
        "for x,y in zip(test_x,test_y):\n",
        "    y_hat = predict_tweet(x, freqs, theta)\n",
        "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
        "        print('THE TWEET IS:', x)\n",
        "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
        "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
      ],
      "metadata": {
        "id": "TcZgkhp1ZzKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ttvcolNOZ1rT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}